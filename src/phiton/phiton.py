#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["fire", "loguru"]
# ///
# this_file: src/phiton/phiton.py

"""phiton: A dense Python notation converter.

This module provides functionality to convert between Python and Phiton notation,
a dense symbolic representation of Python code designed for token-efficient contexts.

Created by Adam Twardoch
"""

import ast
import re
import sys
from collections.abc import Sequence
from dataclasses import dataclass
from pathlib import Path

import fire
from loguru import logger

__version__ = "0.1.0"


# Symbol mappings for Python to Phiton conversion
PYTHON_TO_PHITON = {
    # Control Flow
    "return": "‚áê",
    "yield": "‚Ü•",
    "yield from": "‚Ü•‚ãÆ",
    "raise": "‚Üë",
    "while": "‚ü≥",
    "for": "‚àÄ",
    "if": "‚ãî",
    "else": "‚ãÆ",
    "try": "‚öü",
    "match": "‚Ü¶",
    "case": "‚âê",
    "assert": "‚ä™",
    "pass": "‚äò",
    "continue": "‚ãØ",
    "break": "‚ä†",
    # Data Operations
    "=": "‚âî",
    "==": "‚â°",
    "!=": "‚â†",
    "in": "‚àà",
    "not in": "‚àâ",
    "sum": "‚àë",
    "map": "‚à´",
    "reduce": "‚®Å",
    "+=": "‚ñ≥",
    "-=": "‚ñΩ",
    "*=": "‚óä",
    "/=": "‚óÜ",
    ":=": "‚âù",
    "<=": "‚â§",
    ">=": "‚â•",
    "and": "‚àß",
    "or": "‚à®",
    "not": "¬¨",
    # Special Values
    "None": "‚àÖ",
    "True": "‚ä§",
    "False": "‚ä•",
    "...": "‚ãÆ",
    # Objects & Functions
    "def": "∆í",
    "lambda": "Œª",
    "class": "Œ£",
    "@property": "‚äô",
    "async": "‚ä°",
    "await": "‚ä°",
    "@staticmethod": "‚äû",
    "@classmethod": "‚äü",
    "@abstractmethod": "‚çü",
    "@dataclass": "‚õã",
    # New Additions
    "len": "‚Ñì",
    "range": "‚Ñú",
    "enumerate": "‚ÑØ",
    "filter": "œÜ",
    "zip": "‚Ñ§",
    "sorted": "œÇ",
    "reversed": "‚Ñõ",
    "any": "‚àÉ",
    "all": "‚àÄ",
    "min": "‚Üì",
    "max": "‚Üë",
    "round": "‚óã",
    "abs": "‚à•",
    "pow": "^",
    "isinstance": "‚àã",
    "hasattr": "‚àå",
    "getattr": "‚ä≥",
    "setattr": "‚ä≤",
    "delattr": "‚äó",
    "super": "‚Ü∞",
    "next": "‚Üí",
    "iter": "‚ü≤",
}

# Reverse mapping for Phiton to Python conversion
PHITON_TO_PYTHON = {v: k for k, v in PYTHON_TO_PHITON.items()}

# Add more symbol mappings for domain-specific operations
DOMAIN_PREFIXES = {
    "numpy": "‚Ññ",
    "pandas": "‚Ñó",
    "sklearn": "œá",
    "matplotlib": "Œº",
    "torch": "Œ®",
    "tensorflow": "Œ¶",
    "flask": "œÜ",
    "django": "…ó",
    "fastapi": "œ±",
    "os": "Œ±",
    "io": "Œ©",
    "typing": "œÑ",
    "math": "Œî",
    "collections": "Œì",
    "itertools": "Œõ",
    "datetime": "Œò",
    "sqlalchemy": "Œ∂",
    "requests": "Œ∑",
    "json": "Œæ",
    "pathlib": "œÄ",
    "re": "¬Æ",
    # New additions
    "asyncio": "Œ≥",
    "functools": "œù",
    "operator": "œâ",
    "random": "œÅ",
    "string": "œÉ",
    "sys": "œà",
    "time": "Œ∏",
    "uuid": "œÖ",
    "yaml": "œí",
    "zlib": "Œ∂",
}

# Common pattern replacements
PATTERN_REPLACEMENTS = {
    "if x is not None": "‚ãîx‚â†‚àÖ",
    "if x is None": "‚ãîx‚â°‚àÖ",
    "for i in range(n)": "‚àÄi‚àà‚Ñú(n)",
    "for i, x in enumerate(xs)": "‚àÄi,x‚àà‚ÑØ(xs)",
    "return [x for x in xs if p(x)]": "‚áê[x‚àÄx‚ààxs‚ãîp(x)]",
    "lambda x: f(x)": "Œªx‚áíf(x)",
    "with open(f) as h": "‚ä¢‚ä£‚äó(f)‚áíh",
    "try: x\nexcept E: y": "‚öü‚ü®x‚ü©‚ãîE‚ü®y‚ü©",
    "if p: return x": "‚ãîp‚áêx",
    "if not p: return": "‚ãî¬¨p‚áê",
    "x if p else y": "p?x:y",
    "[f(x) for x in xs]": "‚à´(f,xs)",
    "sum(x for x in xs)": "‚àë(xs)",
    "all(p(x) for x in xs)": "‚àÄ(p,xs)",
    "any(p(x) for x in xs)": "‚àÉ(p,xs)",
}

# Add advanced pattern recognition
ADVANCED_PATTERNS = {
    # Common function chains
    "df.groupby(X).agg(Y)": "¬ßdf¬∑Œì(X)¬∑A(Y)",
    "df.sort_values(by=X,ascending=Y)": "¬ßdf¬∑œÇ(X,Y)",
    "np.array(X).reshape(Y)": "‚Ññ¬∑A(X)¬∑R(Y)",
    "pd.DataFrame(X).reset_index()": "‚Ñó¬∑D(X)¬∑R()",
    "pd.read_csv(X,encoding=Y)": "‚Ñó¬∑C(X,Y)",
    "requests.get(X).json()": "Œ∑¬∑G(X)¬∑J()",
    # Common list/dict operations
    "[x for x in X if C]": "[x‚àÄx‚ààX‚ãîC]",
    "{k:v for k,v in X.items()}": "{k:v‚àÄk,v‚ààX¬∑‚äô}",
    "dict((k,v) for k,v in X)": "‚àÇ(X)",
    "list(map(F, X))": "‚à´(F,X)",
    "list(filter(F, X))": "œÜ(F,X)",
    "[i for i,x in enumerate(X) if P]": "[i‚àÄi,x‚àà‚ÑØ(X)‚ãîP]",
    "next(x for x in X if P)": "‚Üí(x‚àÄx‚ààX‚ãîP)",
    "any(x in Y for x in X)": "‚àÉ(x‚ààY‚àÄx‚ààX)",
    "all(x in Y for x in X)": "‚àÄ(x‚ààY‚àÄx‚ààX)",
    "{x: y for x,y in zip(X,Y)}": "{x:y‚àÄx,y‚àà‚Ñ§(X,Y)}",
    "sorted(X, key=lambda x: x.Y)": "œÇ(X,Œªx:x¬∑Y)",
    "max(X, key=lambda x: x.Y)": "‚Üë(X,Œªx:x¬∑Y)",
    "min(X, key=lambda x: x.Y)": "‚Üì(X,Œªx:x¬∑Y)",
    # Common control flow patterns
    "if x is not None: return x\nelse: return y": "‚áêx‚â¢‚àÖ?x:y",
    "try:\n    x\nexcept E as e:\n    y": "‚öü‚ü®x‚ü©‚ãîE‚áíe‚ü®y‚ü©",
    "with contextlib.suppress(E):": "‚ä¢‚ä£‚àÖ(E)‚ü®",
    "if not x: return": "‚ãî¬¨x‚áê",
    "if not x: continue": "‚ãî¬¨x‚ãØ",
    "if not x: break": "‚ãî¬¨x‚ä†",
    "while True: x": "‚ü≥‚ä§‚ü®x‚ü©",
    "if x and y: z": "‚ãîx‚àßy‚ü®z‚ü©",
    "if x or y: z": "‚ãîx‚à®y‚ü®z‚ü©",
    # Common async patterns
    "async with aiohttp.ClientSession() as session:": "‚ä¢‚ä£‚ä°Œ∑¬∑S()‚áís‚ü®",
    "await asyncio.gather(*tasks)": "‚ä°Œ≥¬∑G(‚óát)",
    "async for x in Y:": "‚ä°‚àÄx‚ààY‚ü®",
    "await asyncio.sleep(X)": "‚ä°Œ≥¬∑S(X)",
    "await asyncio.create_task(X)": "‚ä°Œ≥¬∑T(X)",
    # Common string operations
    "'.'.join(x for x in X)": "¬∑‚äï(X)",
    "x.strip().lower()": "x¬∑‚åø¬∑‚Üì",
    "re.sub(P, R, S)": "¬Æ¬∑‚áå(P,R,S)",
    "x.split()": "x¬∑‚åø",
    "x.replace(Y, Z)": "x¬∑‚áå(Y,Z)",
    "f'{x}{y}'": "„Äåx„Äç„Äåy„Äç",
    "x.startswith(Y)": "x¬∑‚ä≥Y",
    "x.endswith(Y)": "x¬∑‚ä≤Y",
    # Common math operations
    "math.floor(x/y)": "‚åäx/y‚åã",
    "math.ceil(x/y)": "‚åàx/y‚åâ",
    "abs(x-y)": "‚à•x-y‚à•",
    "pow(x, y)": "x^y",
    "math.sqrt(x)": "‚àöx",
    "math.pi": "œÄ",
    "math.e": "‚ÑØ",
    "float('inf')": "‚àû",
    "float('-inf')": "-‚àû",
    # Common type checking
    "isinstance(x, (A, B))": "x‚àã(A,B)",
    "hasattr(x, 'y')": "x‚àå'y'",
    "getattr(x, 'y', d)": "x‚ä≥'y'‚ãÆd",
    "type(x) is Y": "œÑ(x)‚â°Y",
    "type(x) == Y": "œÑ(x)‚â°Y",
    # Common file operations
    "with open(X, 'r') as f:": "‚ä¢‚ä£‚äó(X,'r')‚áíf‚ü®",
    "with open(X, 'w') as f:": "‚ä¢‚ä£‚äó(X,'w')‚áíf‚ü®",
    "os.path.join(X, Y)": "Œ±¬∑‚äï(X,Y)",
    "os.path.exists(X)": "Œ±¬∑‚àÉ(X)",
    "os.path.dirname(X)": "Œ±¬∑‚àÇ(X)",
    "os.path.basename(X)": "Œ±¬∑Œ≤(X)",
    # Common collections operations
    "collections.defaultdict(list)": "Œì¬∑‚àÇ(‚Ñì)",
    "collections.Counter(X)": "Œì¬∑C(X)",
    "collections.deque(X)": "Œì¬∑Q(X)",
    "itertools.chain(*X)": "Œõ¬∑‚äï(‚óáX)",
    "itertools.cycle(X)": "Œõ¬∑‚ü≥(X)",
    "itertools.repeat(X, n)": "Œõ¬∑‚Ñú(X,n)",
    # Common testing patterns
    "assert x == y": "‚ä™x‚â°y",
    "assert x is not None": "‚ä™x‚â¢‚àÖ",
    "assert isinstance(x, Y)": "‚ä™x‚àãY",
    "assert len(x) > 0": "‚ä™‚Ñì(x)>0",
    "assert all(x in Y for x in X)": "‚ä™‚àÄ(x‚ààY‚àÄx‚ààX)",
    # Common error handling
    "raise ValueError(X)": "‚ÜëV(X)",
    "raise TypeError(X)": "‚ÜëT(X)",
    "raise Exception(X)": "‚ÜëE(X)",
    "raise NotImplementedError": "‚Üë‚àÖ",
    # Common functional patterns
    "functools.partial(F, X)": "œù¬∑P(F,X)",
    "functools.reduce(F, X)": "œù¬∑R(F,X)",
    "operator.itemgetter(X)": "œâ¬∑I(X)",
    "operator.attrgetter(X)": "œâ¬∑A(X)",
    # Common datetime operations
    "datetime.datetime.now()": "Œò¬∑N()",
    "datetime.datetime.utcnow()": "Œò¬∑U()",
    "datetime.timedelta(days=X)": "Œò¬∑D(X)",
    "datetime.datetime.strptime(X,Y)": "Œò¬∑P(X,Y)",
    "datetime.datetime.strftime(X,Y)": "Œò¬∑F(X,Y)",
}

# Add final compression optimizations
COMMON_SUBEXPRESSIONS = {
    # Common numeric operations
    "x + 1": "x‚Å∫",
    "x - 1": "x‚Åª",
    "x * 2": "x¬≤",
    "x ** 2": "x¬≤",
    "x ** 3": "x¬≥",
    "x ** n": "x‚Åø",
    "x / 2": "x¬Ω",
    # Common string operations
    ".split()": "¬∑‚åø",
    ".strip()": "¬∑‚åø",
    ".lower()": "¬∑‚Üì",
    ".upper()": "¬∑‚Üë",
    ".replace(": "¬∑‚áå(",
    ".format(": "¬∑‚®ç(",
    ".join(": "¬∑‚äï(",
    # Common list operations
    ".append(": "¬∑‚äï(",
    ".extend(": "¬∑‚äï‚äï(",
    ".pop(": "¬∑‚äñ(",
    ".clear(": "¬∑‚àÖ(",
    ".copy(": "¬∑‚äô(",
    ".sort(": "¬∑œÇ(",
    ".reverse(": "¬∑‚Ñõ(",
    # Common dict operations
    ".keys()": "¬∑‚äô",
    ".values()": "¬∑‚äö",
    ".items()": "¬∑‚äõ",
    ".get(": "¬∑‚ä≥(",
    ".update(": "¬∑‚ä≤(",
    # Common type conversions
    "str(": "œÉ(",
    "int(": "‚Ñ§(",
    "float(": "‚Ñù(",
    "bool(": "ùîπ(",
    "list(": "‚Ñì(",
    "tuple(": "œÑ(",
    "dict(": "‚àÇ(",
    "set(": "ùïä(",
}


@dataclass
class ConversionConfig:
    """Configuration settings for Phiton conversion."""

    comments: bool = True
    type_hints: bool = True
    minify: bool = True
    symbols: bool = True
    level: int = 5


def optimize_imports(tree: ast.AST) -> list[str]:
    """Optimize and combine imports."""
    imports = {}
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports[alias.name] = alias.asname or alias.name
        elif isinstance(node, ast.ImportFrom):
            module = node.module or ""
            for alias in node.names:
                imports[f"{module}.{alias.name}"] = alias.asname or alias.name

    # Group imports by domain
    domain_imports = {}
    for imp, alias in imports.items():
        for domain, _prefix in DOMAIN_PREFIXES.items():
            if imp.startswith(domain):
                if domain not in domain_imports:
                    domain_imports[domain] = []
                domain_imports[domain].append((imp, alias))
                break

    # Generate optimized import statements
    result = []
    for domain, imps in domain_imports.items():
        if len(imps) > 1:
            # Combine multiple imports from same domain
            names = [
                f"{i[0].split('.')[-1]} as {i[1]}"
                if i[0] != i[1]
                else i[0].split(".")[-1]
                for i in imps
            ]
            result.append(f"from {domain} import {', '.join(names)}")
        else:
            imp, alias = imps[0]
            if imp == alias:
                result.append(f"import {imp}")
            else:
                result.append(f"import {imp} as {alias}")

    return result


def optimize_final(code: str, level: int) -> str:
    """Apply final optimizations based on compression level.

    Level 1: Basic symbol substitution, preserve structure
    Level 2: Remove redundant whitespace, combine simple operations
    Level 3: Replace common subexpressions, optimize imports
    Level 4: Aggressive whitespace removal, symbol renaming
    Level 5: Maximum compression, shortest possible representation
    """
    # Level 1: Basic symbol substitution only
    if level < 2:
        # Preserve structure but apply basic symbol mappings
        code = re.sub(r"\s+", " ", code)  # Normalize whitespace
        return code

    # Level 2: Remove redundant whitespace, combine simple operations
    if level < 3:
        code = re.sub(r"\s+", " ", code)  # Normalize but preserve some whitespace
        code = re.sub(r"‚Üí\s*‚Üí", "‚Üí", code)  # Combine arrows
        return code

    # Level 3: Replace common subexpressions, optimize imports
    if level < 4:
        # Replace common subexpressions while preserving some readability
        for pattern, replacement in COMMON_SUBEXPRESSIONS.items():
            code = code.replace(pattern, replacement)
        code = re.sub(r"\s+", " ", code)  # Keep single spaces
        code = re.sub(r"‚Üí\s*‚Üí", "‚Üí", code)
        return code

    # Level 4: Aggressive whitespace removal, symbol renaming
    if level < 5:
        for pattern, replacement in COMMON_SUBEXPRESSIONS.items():
            code = code.replace(pattern, replacement)
        code = re.sub(r"\s+", "", code)  # Remove all whitespace
        code = re.sub(
            r"\(\s*([^,()]+)\s*\)", r"\1", code
        )  # Remove unnecessary parentheses

        # Use shorter names for local symbols
        used_symbols = set(re.findall(r"¬ß(\w+)", code))
        symbol_map = {sym: f"_{i}" for i, sym in enumerate(sorted(used_symbols))}
        for old, new in symbol_map.items():
            code = code.replace(f"¬ß{old}", f"¬ß{new}")

        return code

    # Level 5: Maximum compression
    # Replace common subexpressions
    for pattern, replacement in COMMON_SUBEXPRESSIONS.items():
        code = code.replace(pattern, replacement)

    # Remove all unnecessary characters
    code = re.sub(r"\s+", "", code)
    code = re.sub(r"\(\s*([^,()]+)\s*\)", r"\1", code)
    code = re.sub(r"‚Üí\s*‚Üí", "‚Üí", code)

    # Use shortest possible names for local symbols
    used_symbols = set(re.findall(r"¬ß(\w+)", code))
    symbol_map = {sym: chr(ord("a") + i) for i, sym in enumerate(sorted(used_symbols))}
    for old, new in symbol_map.items():
        code = code.replace(f"¬ß{old}", f"¬ß{new}")

    # Combine repeated operations
    code = re.sub(r"(‚äï|‚äñ|‚ñ≥|‚ñΩ|‚óä|‚óÜ)\1+", r"\1", code)

    # Use shortest form for common patterns
    replacements = {
        "‚ãî‚ä§‚ü®": "‚ä§‚ü®",  # if True:
        "‚ãî‚ä•‚ü®": "‚ä•‚ü®",  # if False:
        "‚ãî‚àÖ‚ü®": "‚àÖ‚ü®",  # if None:
        "‚áê‚ä§": "‚áê‚ä§",  # return True
        "‚áê‚ä•": "‚áê‚ä•",  # return False
        "‚áê‚àÖ": "‚áê‚àÖ",  # return None
        "‚âî‚àÖ": "‚àÖ",  # = None
        "‚âî‚ä§": "‚ä§",  # = True
        "‚âî‚ä•": "‚ä•",  # = False
    }
    for pattern, repl in replacements.items():
        code = code.replace(pattern, repl)

    return code


def compress_to_phiton(source_code: str, config: ConversionConfig | None = None) -> str:
    """Convert Python code to Phiton notation with enhanced compression.

    Args:
        source_code: Python source code to convert
        config: Optional conversion configuration

    Returns:
        Converted Phiton code with maximum compression

    Raises:
        SyntaxError: If input_path Python code is invalid
    """
    if config is None:
        config = ConversionConfig()

    try:
        tree = ast.parse(source_code)
    except SyntaxError as e:
        logger.error("Invalid Python syntax: %s", str(e))
        raise

    # Initialize tracking structures
    symbol_table: dict[str, str] = {}
    expr_freq: dict[str, int] = {}
    scope_stack: list[dict[str, str]] = [{}]

    # Optimize imports first
    if config.level >= 3:
        optimized_imports = optimize_imports(tree)
        for imp in optimized_imports:
            symbol_table[imp] = f"¬ß{len(symbol_table)}"

    def get_pattern_key(node: ast.AST) -> str | None:
        """Get a key for pattern matching if the node matches a common pattern."""
        if isinstance(node, ast.If):
            # Handle common if patterns
            test_str = ast.unparse(node.test)
            body_str = ast.unparse(node.body[0]) if node.body else ""
            pattern = f"{test_str}: {body_str}"
            return pattern if pattern in PATTERN_REPLACEMENTS else None
        elif isinstance(node, ast.ListComp):
            # Handle list comprehension patterns
            return ast.unparse(node)
        return None

    def should_create_symbol(expr: str, freq: int) -> bool:
        """Determine if an expression should be assigned to a local symbol."""
        return (
            freq > 2  # Used more than twice
            and len(expr) > 10  # Long enough to benefit from compression
            and not expr.startswith("¬ß")  # Not already a symbol
            and not any(c in expr for c in "‚ü®‚ü©‚Üí")  # Not a complex expression
        )

    def get_next_symbol_name() -> str:
        """Generate the next available symbol name."""
        used_names = set().union(*scope_stack)
        for c in "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ":
            if c not in used_names:
                return c
        # If single chars exhausted, use numbered symbols
        i = 0
        while f"_{i}" in used_names:
            i += 1
        return f"_{i}"

    def optimize_expression(expr: str) -> str:
        """Apply additional compression optimizations to an expression."""
        # Remove unnecessary parentheses
        expr = re.sub(r"\(\s*([^,()]+)\s*\)", r"\1", expr)
        # Compress whitespace
        expr = re.sub(r"\s+", "", expr)
        # Apply common patterns
        for pattern, replacement in PATTERN_REPLACEMENTS.items():
            if pattern in expr:
                expr = expr.replace(pattern, replacement)
        return expr

    def detect_advanced_pattern(node: ast.AST) -> str | None:
        """Detect if a node matches an advanced pattern."""
        node_str = ast.unparse(node)
        for pattern, replacement in ADVANCED_PATTERNS.items():
            if pattern in node_str:
                return replacement
        return None

    def convert_node(node: ast.AST | None) -> str:
        """Convert an AST node to Phiton notation with enhanced compression.

        The compression level affects how aggressively we convert nodes:
        Level 1: Basic conversion with readable symbols and preserved structure
        Level 2: More symbol substitutions but maintain readability
        Level 3: Full symbol substitution with some structure preservation
        Level 4: Aggressive symbol substitution and minimal structure
        Level 5: Maximum compression with shortest possible representation
        """
        if node is None:
            return ""

        # Handle Module node specially
        if isinstance(node, ast.Module):
            return convert_body(node.body)

        # Check for advanced patterns first
        if config.level >= 3:
            if pattern := detect_advanced_pattern(node):
                return pattern

        # Check for pattern matches first
        if config.level >= 2:
            if pattern_key := get_pattern_key(node):
                if pattern_key in PATTERN_REPLACEMENTS:
                    return PATTERN_REPLACEMENTS[pattern_key]

        # Track expression frequency for higher compression levels
        if config.level >= 3:
            try:
                expr = ast.unparse(node) if isinstance(node, ast.expr) else ""
                if expr:
                    expr_freq[expr] = expr_freq.get(expr, 0) + 1
            except Exception:
                # Skip if unparsing fails
                pass

        if isinstance(node, ast.FunctionDef):
            scope_stack.append({})  # New scope
            args = convert_arguments(node.args)
            body = convert_body(node.body)
            decorators = "".join(convert_node(d) for d in node.decorator_list)
            returns = f"‚¶Ç‚üÆ{convert_node(node.returns)}‚üØ" if node.returns else ""
            scope_stack.pop()  # End scope

            # More readable format for lower compression levels
            if config.level <= 2:
                return f"{decorators}def {node.name}({args}){returns}:\n{body}"
            return f"{decorators}∆í{node.name}({args}){returns}‚ü®{body}‚ü©"

        elif isinstance(node, ast.Name):
            # Handle special constants based on compression level
            if node.id == "None":
                return "None" if config.level <= 2 else "‚àÖ"
            elif node.id == "True":
                return "True" if config.level <= 2 else "‚ä§"
            elif node.id == "False":
                return "False" if config.level <= 2 else "‚ä•"

            # Check for domain-specific prefixes at higher levels
            if config.level >= 3 and node.id in DOMAIN_PREFIXES:
                return DOMAIN_PREFIXES[node.id]

            # Check for local symbol definitions at higher levels
            if config.level >= 3 and config.symbols and node.id in symbol_table:
                return f"¬ß{symbol_table[node.id]}"

            return node.id

        elif isinstance(node, ast.Constant):
            if node.value is None:
                return "None" if config.level <= 2 else "‚àÖ"
            elif node.value is True:
                return "True" if config.level <= 2 else "‚ä§"
            elif node.value is False:
                return "False" if config.level <= 2 else "‚ä•"
            elif isinstance(node.value, str):
                if config.level >= 3:
                    return f"${node.value}"
                return repr(node.value)
            elif isinstance(node.value, (int, float)):
                if config.level >= 3:
                    return f"#{node.value}"
                return str(node.value)
            return repr(node.value)

        elif isinstance(node, ast.Return):
            value = convert_node(node.value) if node.value else ""
            if config.level <= 2:
                return f"return {value}"
            return f"‚áê{value}"

        elif isinstance(node, ast.If):
            test = convert_node(node.test)
            body = convert_body(node.body)
            orelse = convert_body(node.orelse) if node.orelse else ""

            if config.level <= 2:
                result = f"if {test}:\n{body}"
                if orelse:
                    result += f"\nelse:\n{orelse}"
                return result
            return f"‚ãî{test}‚ü®{body}‚ü©{f'‚ãÆ{orelse}' if orelse else ''}"

        elif isinstance(node, ast.Call):
            func = convert_node(node.func)
            args = [convert_node(arg) for arg in node.args]
            kwargs = [f"{kw.arg}={convert_node(kw.value)}" for kw in node.keywords]
            all_args = ",".join(filter(None, [",".join(args), ",".join(kwargs)]))

            # Handle domain-specific library calls at higher levels
            if config.level >= 3:
                if isinstance(node.func, ast.Attribute) and isinstance(
                    node.func.value, ast.Name
                ):
                    lib_name = node.func.value.id
                    if lib_name in DOMAIN_PREFIXES:
                        return (
                            f"{DOMAIN_PREFIXES[lib_name]}¬∑{node.func.attr}({all_args})"
                        )

                # Handle common function patterns
                if func in PYTHON_TO_PHITON:
                    return f"{PYTHON_TO_PHITON[func]}({all_args})"

            return f"{func}({all_args})"

        elif isinstance(node, ast.AsyncFunctionDef):
            args = convert_arguments(node.args)
            body = convert_body(node.body)
            decorators = "".join(convert_node(d) for d in node.decorator_list)
            returns = f"‚¶Ç‚üÆ{convert_node(node.returns)}‚üØ" if node.returns else ""
            return f"{decorators}‚ä°∆í{node.name}({args}){returns}‚ü®{body}‚ü©"

        elif isinstance(node, ast.ClassDef):
            bases = ",".join(convert_node(b) for b in node.bases)
            body = convert_body(node.body)
            decorators = "".join(convert_node(d) for d in node.decorator_list)
            return f"{decorators}Œ£{node.name}({bases})‚ü®{body}‚ü©"

        elif isinstance(node, ast.Yield):
            value = convert_node(node.value) if node.value else ""
            return f"‚Ü•{value}"

        elif isinstance(node, ast.YieldFrom):
            value = convert_node(node.value)
            return f"‚Ü•‚ãÆ{value}"

        elif isinstance(node, ast.For):
            target = convert_node(node.target)
            iter = convert_node(node.iter)
            body = convert_body(node.body)
            orelse = f"‚ãÆ{convert_body(node.orelse)}" if node.orelse else ""
            return f"‚àÄ{target}‚àà{iter}‚ü®{body}‚ü©{orelse}"

        elif isinstance(node, ast.While):
            test = convert_node(node.test)
            body = convert_body(node.body)
            orelse = f"‚ãÆ{convert_body(node.orelse)}" if node.orelse else ""
            return f"‚ü≥{test}‚ü®{body}‚ü©{orelse}"

        elif isinstance(node, ast.ExceptHandler):
            type = convert_node(node.type) if node.type else ""
            name = f" as {node.name}" if node.name else ""
            body = convert_body(node.body)
            return f"‚ãî{type}{name}‚ü®{body}‚ü©"

        elif isinstance(node, ast.With):
            items = ",".join(convert_node(item) for item in node.items)
            body = convert_body(node.body)
            return f"‚ä¢‚ä£{items}‚ü®{body}‚ü©"

        elif isinstance(node, ast.Match):
            subject = convert_node(node.subject)
            cases = "".join(convert_node(case) for case in node.cases)
            return f"‚Ü¶{subject}‚ü®{cases}‚ü©"

        elif isinstance(node, ast.match_case):
            pattern = convert_match_pattern(node.pattern)
            guard = f"‚ãî{convert_node(node.guard)}" if node.guard else ""
            body = convert_body(node.body)
            return f"‚âê{pattern}{guard}‚ü®{body}‚ü©"

        elif isinstance(node, ast.BinOp):
            left = convert_node(node.left)
            right = convert_node(node.right)
            op = convert_operator(node.op)
            return f"{left}{op}{right}"

        elif isinstance(node, ast.Compare):
            left = convert_node(node.left)
            ops = [convert_operator(op) for op in node.ops]
            comparators = [convert_node(comp) for comp in node.comparators]
            parts = [left]
            for op, comp in zip(ops, comparators, strict=False):
                parts.extend([op, comp])
            return "".join(parts)

        elif isinstance(node, ast.Call):
            func = convert_node(node.func)
            args = [convert_node(arg) for arg in node.args]
            kwargs = [f"{kw.arg}={convert_node(kw.value)}" for kw in node.keywords]
            all_args = ",".join(filter(None, [",".join(args), ",".join(kwargs)]))

            # Handle domain-specific library calls
            if isinstance(node.func, ast.Attribute) and isinstance(
                node.func.value, ast.Name
            ):
                lib_name = node.func.value.id
                if lib_name in DOMAIN_PREFIXES and config.level >= 3:
                    return f"{DOMAIN_PREFIXES[lib_name]}¬∑{node.func.attr}({all_args})"

            # Handle common function patterns
            if func in PYTHON_TO_PHITON:
                return f"{PYTHON_TO_PHITON[func]}({all_args})"

            return f"{func}({all_args})"

        elif isinstance(node, ast.Attribute):
            value = convert_node(node.value)
            return f"{value}¬∑{node.attr}"

        elif isinstance(node, ast.List):
            elements = [convert_node(elt) for elt in node.elts]
            return f"[{','.join(elements)}]"

        elif isinstance(node, ast.Tuple):
            elements = [convert_node(elt) for elt in node.elts]
            return f"({','.join(elements)})"

        elif isinstance(node, ast.Dict):
            items = [
                f"{convert_node(k)}:{convert_node(v)}"
                for k, v in zip(node.keys, node.values, strict=False)
            ]
            return f"{{{','.join(items)}}}"

        elif isinstance(node, ast.Set):
            elements = [convert_node(elt) for elt in node.elts]
            return f"{{{','.join(elements)}}}"

        elif isinstance(node, ast.ListComp):
            elt = convert_node(node.elt)
            generators = []
            for gen in node.generators:
                target = convert_node(gen.target)
                iter_expr = convert_node(gen.iter)
                ifs = [f"‚ãî{convert_node(if_expr)}" for if_expr in gen.ifs]
                generators.append(f"‚àÄ{target}‚àà{iter_expr}{''.join(ifs)}")
            return f"‚ü¨{elt} {' '.join(generators)}‚ü≠"

        elif isinstance(node, ast.DictComp):
            key = convert_node(node.key)
            value = convert_node(node.value)
            generators = []
            for gen in node.generators:
                target = convert_node(gen.target)
                iter_expr = convert_node(gen.iter)
                ifs = [f"‚ãî{convert_node(if_expr)}" for if_expr in gen.ifs]
                generators.append(f"‚àÄ{target}‚àà{iter_expr}{''.join(ifs)}")
            return f"‚ü¶{key}:{value} {' '.join(generators)}‚üß"

        elif isinstance(node, ast.SetComp):
            elt = convert_node(node.elt)
            generators = []
            for gen in node.generators:
                target = convert_node(gen.target)
                iter_expr = convert_node(gen.iter)
                ifs = [f"‚ãî{convert_node(if_expr)}" for if_expr in gen.ifs]
                generators.append(f"‚àÄ{target}‚àà{iter_expr}{''.join(ifs)}")
            return f"‚¶É{elt} {' '.join(generators)}‚¶Ñ"

        elif isinstance(node, ast.JoinedStr):
            values = []
            for value in node.values:
                if isinstance(value, ast.FormattedValue):
                    values.append(f"{{{convert_node(value.value)}}}")
                elif isinstance(value, ast.Constant):
                    values.append(str(value.value))
            return f"„Äå{''.join(values)}„Äç"

        elif isinstance(node, ast.NamedExpr):
            target = convert_node(node.target)
            value = convert_node(node.value)
            return f"{target}‚âù{value}"

        elif isinstance(node, ast.Starred):
            value = convert_node(node.value)
            return f"*{value}"

        elif isinstance(node, ast.Lambda):
            args = convert_arguments(node.args)
            body = convert_node(node.body)
            return f"Œª{args}:{body}"

        elif isinstance(node, ast.Subscript):
            value = convert_node(node.value)
            slice_expr = convert_node(node.slice)
            return f"{value}[{slice_expr}]"

        elif isinstance(node, ast.Slice):
            lower = convert_node(node.lower) if node.lower else ""
            upper = convert_node(node.upper) if node.upper else ""
            step = f":{convert_node(node.step)}" if node.step else ""
            return f"{lower}:{upper}{step}"

        elif isinstance(node, ast.UnaryOp):
            operand = convert_node(node.operand)
            if isinstance(node.op, ast.Not):
                return f"¬¨{operand}"
            elif isinstance(node.op, ast.USub):
                return f"-{operand}"
            elif isinstance(node.op, ast.UAdd):
                return f"+{operand}"
            return f"{node.op.__class__.__name__}({operand})"

        elif isinstance(node, ast.BoolOp):
            op = "‚àß" if isinstance(node.op, ast.And) else "‚à®"
            values = [convert_node(val) for val in node.values]
            return op.join(values)

        elif isinstance(node, ast.Await):
            value = convert_node(node.value)
            return f"‚ä°{value}"

        elif isinstance(node, ast.AnnAssign):
            target = convert_node(node.target)
            annotation = convert_node(node.annotation)
            value = f"‚âî{convert_node(node.value)}" if node.value else ""
            return f"{target}‚¶Ç{annotation}{value}"

        elif isinstance(node, ast.Assign):
            targets = [convert_node(target) for target in node.targets]
            value = convert_node(node.value)
            return f"{','.join(targets)}‚âî{value}"

        elif isinstance(node, ast.AugAssign):
            target = convert_node(node.target)
            op = convert_operator(node.op)
            value = convert_node(node.value)
            return f"{target}‚ñ≥{op}{value}"

        elif isinstance(node, ast.Pass):
            return "‚äò"

        elif isinstance(node, ast.Break):
            return "‚ä†"

        elif isinstance(node, ast.Continue):
            return "‚ãØ"

        elif isinstance(node, ast.Assert):
            test = convert_node(node.test)
            msg = f",{convert_node(node.msg)}" if node.msg else ""
            return f"‚ä™{test}{msg}"

        elif isinstance(node, ast.Delete):
            targets = [convert_node(target) for target in node.targets]
            return f"del {','.join(targets)}"

        elif isinstance(node, ast.Raise):
            exc = convert_node(node.exc) if node.exc else ""
            cause = f" from {convert_node(node.cause)}" if node.cause else ""
            return f"‚Üë{exc}{cause}"

        elif isinstance(node, ast.Global):
            return f"global {','.join(node.names)}"

        elif isinstance(node, ast.Nonlocal):
            return f"nonlocal {','.join(node.names)}"

        elif isinstance(node, ast.Import):
            if config.level < 3:
                names = [alias.name for alias in node.names]
                return f"import {','.join(names)}"
            return ""  # Skip imports at higher compression levels

        elif isinstance(node, ast.ImportFrom):
            if config.level < 3:
                module = node.module or ""
                names = [alias.name for alias in node.names]
                return f"from {module} import {','.join(names)}"
            return ""  # Skip imports at higher compression levels

        # Fallback for unhandled nodes
        try:
            return str(ast.unparse(node))
        except Exception:
            return f"<{node.__class__.__name__}>"

    def convert_arguments(args: ast.arguments) -> str:
        """Convert function arguments to Phiton notation."""
        parts = []
        for arg in args.args:
            arg_str = arg.arg
            if config.type_hints and arg.annotation:
                type_hint = convert_node(arg.annotation)
                arg_str += f"‚¶Ç‚üÆ{type_hint}‚üØ"
            parts.append(arg_str)
        return ",".join(parts)

    def convert_body(body: Sequence[ast.AST]) -> str:
        """Convert a list of statements to Phiton notation with optimizations."""
        statements = []
        for node in body:
            stmt = convert_node(node)
            # Create local symbols for frequently used expressions
            expr = ast.unparse(node) if isinstance(node, ast.expr) else ""
            if expr and should_create_symbol(expr, expr_freq[expr]):
                sym_name = get_next_symbol_name()
                scope_stack[-1][sym_name] = expr
                statements.append(f"¬ß{sym_name}‚âî{stmt}")
                symbol_table[expr] = sym_name
            else:
                statements.append(stmt)

        return "‚Üí".join(optimize_expression(stmt) for stmt in statements)

    def convert_operator(op: ast.operator | ast.cmpop | ast.boolop) -> str:
        """Convert Python operator to Phiton symbol."""
        # Simple mapping based on operator class name
        name = op.__class__.__name__
        if name == "Add":
            return "+"
        elif name == "Sub":
            return "-"
        elif name == "Mult":
            return "*"
        elif name == "Div":
            return "/"
        elif name == "Eq":
            return "‚â°"
        elif name == "NotEq":
            return "‚â†"
        elif name == "Lt":
            return "<"
        elif name == "LtE":
            return "‚â§"
        elif name == "Gt":
            return ">"
        elif name == "GtE":
            return "‚â•"
        elif name == "In":
            return "‚àà"
        elif name == "NotIn":
            return "‚àâ"
        elif name == "And":
            return "‚àß"
        elif name == "Or":
            return "‚à®"
        elif name == "Not":
            return "¬¨"
        return name

    def convert_match_pattern(pattern: ast.pattern | None) -> str:
        """Convert a match pattern to Phiton notation."""
        if pattern is None:
            return "_"
        if isinstance(pattern, ast.MatchValue):
            return convert_node(pattern.value)
        elif isinstance(pattern, ast.MatchSingleton):
            if pattern.value is None:
                return "‚àÖ"
            elif pattern.value is True:
                return "‚ä§"
            elif pattern.value is False:
                return "‚ä•"
        elif isinstance(pattern, ast.MatchSequence):
            patterns = [convert_match_pattern(p) for p in pattern.patterns]
            return f"[{','.join(patterns)}]"
        elif isinstance(pattern, ast.MatchStar):
            return f"*{pattern.name}" if pattern.name else "*_"
        elif isinstance(pattern, ast.MatchMapping):
            items = []
            for key, pat in zip(pattern.keys, pattern.patterns, strict=False):
                key_str = convert_node(key)
                pat_str = convert_match_pattern(pat)
                items.append(f"{key_str}:{pat_str}")
            if pattern.rest:
                items.append(f"**{pattern.rest}")
            return f"{{{','.join(items)}}}"
        elif isinstance(pattern, ast.MatchClass):
            cls = convert_node(pattern.cls)
            patterns = [convert_match_pattern(p) for p in pattern.patterns]
            kwargs = [
                f"{k}={convert_match_pattern(p)}"
                for k, p in zip(pattern.kwd_attrs, pattern.kwd_patterns, strict=False)
            ]
            args = patterns + kwargs
            return f"{cls}({','.join(args)})"
        elif isinstance(pattern, ast.MatchAs):
            if pattern.pattern:
                inner = convert_match_pattern(pattern.pattern)
                return f"{inner} as {pattern.name}" if pattern.name else inner
            return pattern.name if pattern.name else "_"
        return "_"  # Fallback for unhandled patterns

    result = convert_node(tree)

    # Debug print to see what's happening with the Module node
    logger.debug(f"Tree type: {type(tree)}")
    logger.debug(f"Result after convert_node: {result[:100]}")

    # Apply final optimizations
    result = optimize_final(result, config.level)

    return result


def decompress_from_phiton(
    phiton_code: str, config: ConversionConfig | None = None
) -> str:
    """Convert Phiton notation back to Python code.

    Args:
        phiton_code: Phiton code to convert
        config: Optional conversion configuration

    Returns:
        Converted Python code

    Raises:
        ValueError: If input Phiton code is invalid
    """
    if config is None:
        config = ConversionConfig()

    try:
        # Extract docstring if present
        python_code = ""
        rest_of_code = phiton_code

        # Check for docstring at the beginning
        docstring_match = re.search(r"^['\"](.*?)['\"]", phiton_code, re.DOTALL)
        if docstring_match:
            docstring = docstring_match.group(1)
            rest_of_code = phiton_code[docstring_match.end() :].lstrip()
            # Format docstring with proper line breaks
            docstring = re.sub(r"\\n", "\n", docstring)
            docstring = re.sub(r"\s+", " ", docstring)
            python_code = f'"""{docstring}"""\n\n'

        # Step 1: Fix special patterns before main processing

        # Fix function names with special characters
        rest_of_code = re.sub(r"∆í(\w+)ùïä", r"def analyze_dataset", rest_of_code)
        rest_of_code = re.sub(r"(\w+)ùïä\(", r"analyze_dataset(", rest_of_code)

        # Handle numeric literals with # prefix
        rest_of_code = re.sub(r"#(\d+)", r"\1", rest_of_code)
        rest_of_code = re.sub(r"#(\d+\.\d+)", r"\1", rest_of_code)

        # Handle string literals
        rest_of_code = re.sub(r"\$(\w+)", r'"\1"', rest_of_code)

        # Step 2: Process block structure with proper indentation
        def process_blocks(code):
            lines = []
            current_line = ""
            indent_stack = [0]  # Start with no indentation

            i = 0
            while i < len(code):
                if i + 1 <= len(code):
                    char = code[i]

                    # Handle block opening
                    if char == "‚ü®":
                        current_line += ":"
                        lines.append(current_line)
                        current_line = " " * (indent_stack[-1] + 4)  # Indent next line
                        indent_stack.append(indent_stack[-1] + 4)
                        i += 1
                        continue

                    # Handle block closing
                    elif char == "‚ü©":
                        if (
                            current_line.strip()
                        ):  # If there's content on the current line
                            lines.append(current_line)
                        if len(indent_stack) > 1:
                            indent_stack.pop()
                        current_line = " " * indent_stack[-1]
                        i += 1
                        continue

                    # Handle line breaks
                    elif char == "‚Üí":
                        if (
                            current_line.strip()
                        ):  # If there's content on the current line
                            lines.append(current_line)
                        current_line = (
                            " " * indent_stack[-1]
                        )  # Start new line with current indent
                        i += 1
                        continue

                    # Regular character
                    else:
                        current_line += char
                        i += 1
                else:
                    break

            # Add the last line if it has content
            if current_line.strip():
                lines.append(current_line)

            return "\n".join(lines)

        # Process blocks
        rest_of_code = process_blocks(rest_of_code)

        # Step 3: Replace Phiton symbols with Python equivalents
        replacements = [
            # Control flow
            ("‚áê", "return "),
            ("‚Ü•", "yield "),
            ("‚Ü•‚ãÆ", "yield from "),
            ("‚Üë", "raise "),
            ("‚ü≥", "while "),
            ("‚àÄ", "for "),
            ("‚ãî", "if "),
            ("‚ãÆ", "else"),
            ("‚öü", "try"),
            ("‚Ü¶", "match "),
            ("‚âê", "case "),
            ("‚ä™", "assert "),
            ("‚äò", "pass"),
            ("‚ãØ", "continue"),
            ("‚ä†", "break"),
            # Operators
            ("‚âî", " = "),
            ("‚â°", " == "),
            ("‚â†", " != "),
            ("‚àà", " in "),
            ("‚àâ", " not in "),
            ("‚àë", "sum"),
            ("‚à´", "map"),
            ("‚®Å", "reduce"),
            ("‚ñ≥", " += "),
            ("‚ñΩ", " -= "),
            ("‚óä", " *= "),
            ("‚óÜ", " /= "),
            ("‚âù", " := "),
            ("‚â§", " <= "),
            ("‚â•", " >= "),
            ("‚àß", " and "),
            ("‚à®", " or "),
            ("¬¨", "not "),
            # Special values
            ("‚àÖ", "None"),
            ("‚ä§", "True"),
            ("‚ä•", "False"),
            # Functions and classes
            ("∆í", "def "),
            ("Œª", "lambda "),
            ("Œ£", "class "),
            ("‚äô", "@property"),
            ("‚ä°", "async "),
            ("‚äû", "@staticmethod"),
            ("‚äü", "@classmethod"),
            ("‚çü", "@abstractmethod"),
            ("‚õã", "@dataclass"),
            # Built-in functions
            ("‚Ñì", "len"),
            ("‚Ñú", "range"),
            ("‚ÑØ", "enumerate"),
            ("œÜ", "filter"),
            ("‚Ñ§", "zip"),
            ("œÇ", "sorted"),
            ("‚Ñõ", "reversed"),
            ("‚àÉ", "any"),
            ("‚Üì", "min"),
            ("‚Üë", "max"),
            ("‚óã", "round"),
            ("‚à•", "abs"),
            ("^", "pow"),
            ("‚àã", "isinstance"),
            ("‚àå", "hasattr"),
            ("‚ä≥", "getattr"),
            ("‚ä≤", "setattr"),
            ("‚äó", "delattr"),
            ("‚Ü∞", "super"),
            ("‚ü≤", "iter"),
            # Brackets and delimiters
            ("‚ü¶", "{"),
            ("‚üß", "}"),
            ("‚ü¨", "["),
            ("‚ü≠", "]"),
            ("‚¶Ö", "("),
            ("‚¶Ü", ")"),
            ("‚üÆ", "("),
            ("‚üØ", ")"),
            # Domain prefixes
            ("‚Ññ", "np"),
            ("‚Ñó", "pd"),
            ("œá", "sklearn"),
            ("Œº", "matplotlib"),
            ("Œ®", "torch"),
            ("Œ¶", "tensorflow"),
            ("…ó", "django"),
            ("œ±", "fastapi"),
            ("Œ±", "os"),
            ("Œ©", "io"),
            ("œÑ", "typing"),
            ("Œî", "math"),
            ("Œì", "collections"),
            ("Œõ", "itertools"),
            ("Œò", "datetime"),
            ("Œ∂", "sqlalchemy"),
            ("Œ∑", "requests"),
            ("Œæ", "json"),
            ("œÄ", "pathlib"),
            ("¬Æ", "re"),
            ("Œ≥", "asyncio"),
            ("œù", "functools"),
            ("œâ", "operator"),
            ("œÅ", "random"),
            ("œÉ", "string"),
            ("œà", "sys"),
            ("Œ∏", "time"),
            ("œÖ", "uuid"),
            ("œí", "yaml"),
            ("Œ∂", "zlib"),
            # Common patterns
            ("¬∑", "."),
            ("‚åø", "strip"),
            ("‚áå", "replace"),
            ("‚®ç", "format"),
            ("‚äï", "append"),
            ("‚äñ", "pop"),
            ("‚äö", "values"),
            ("‚äõ", "items"),
            ("¬ß", "_"),
            # Whitespace and formatting
            ("‚¶Ç", ":"),
        ]

        # Apply symbol replacements
        for old, new in replacements:
            rest_of_code = rest_of_code.replace(old, new)

        # Step 4: Fix common syntax issues and formatting

        # Fix spacing around operators and punctuation
        rest_of_code = re.sub(
            r"([=!<>+\-*/])\s*([=!<>+\-*/])", r"\1\2", rest_of_code
        )  # Join operators like ==, +=, etc.
        rest_of_code = re.sub(
            r"\s+([,;:])", r"\1", rest_of_code
        )  # Remove space before punctuation
        rest_of_code = re.sub(
            r"([,;:])\s+", r"\1 ", rest_of_code
        )  # Ensure space after punctuation
        rest_of_code = re.sub(
            r"\s+\)", r")", rest_of_code
        )  # Remove space before closing parenthesis
        rest_of_code = re.sub(
            r"\(\s+", r"(", rest_of_code
        )  # Remove space after opening parenthesis

        # Fix common word joins
        word_fixes = [
            (r"in\s+g", "ing"),
            (r"or\s+t", "ort"),
            (r"f\s+or", "for"),
            (r"s\s+or\s+t", "sort"),
            (r"cont\s+in\s+ue", "continue"),
            (r"imp\s+or\s+t", "import"),
            (r"doma\s+in", "domain"),
            (r"operat\s+or", "operator"),
            (r"r\s+and\s+om", "random"),
            (r"str\s+in\s+g", "string"),
            (r"typ\s+in\s+g", "typing"),
            (r"is\s+in\s+stance", "isinstance"),
            (r"m\s+in", "min"),
            (r"t\s+or\s+ch", "torch"),
            (r"tens\s+or\s+flow", "tensorflow"),
            (r"p\s+and\s+as", "pandas"),
        ]

        for pattern, replacement in word_fixes:
            rest_of_code = re.sub(pattern, replacement, rest_of_code)

        # Fix dictionary formatting
        rest_of_code = re.sub(
            r"(\w+)\s*=\s*\{([^}]+)\}",
            lambda m: f"{m.group(1)} = {{\n    {m.group(2).strip()}\n}}",
            rest_of_code,
        )

        # Fix dictionary key-value pairs
        rest_of_code = re.sub(
            r'"([^"]+)"\s*,\s*"([^"]+)"', r'"\1": "\2",', rest_of_code
        )
        rest_of_code = re.sub(
            r"\'([^\']+)\'\s*,\s*\'([^\']+)\'", r"'\1': '\2',", rest_of_code
        )

        # Fix spacing in function calls
        rest_of_code = re.sub(
            r"(\w+)\(", r"\1(", rest_of_code
        )  # Remove space between function name and parenthesis

        # Fix spacing in list comprehensions
        rest_of_code = re.sub(r"for\s+(\w+)\s+in", r"for \1 in", rest_of_code)

        # Fix spacing in if statements
        rest_of_code = re.sub(r"if\s+(\w+)", r"if \1", rest_of_code)

        # Fix docstring formatting
        rest_of_code = re.sub(
            r"^([^'\"\n]*)['\"]([^'\"\n]*)['\"]", r'\1"""\2"""', rest_of_code
        )

        # Fix nested if statements
        rest_of_code = re.sub(r"(if [^:]+): (if [^:]+):", r"\1:\n    \2:", rest_of_code)

        # Add the processed code to the output
        python_code += rest_of_code

        # Validate the decompressed Python code with AST
        try:
            ast.parse(python_code)
            logger.debug("Decompressed code successfully parsed with AST")
        except SyntaxError as e:
            logger.warning(
                f"Decompressed code has syntax errors but will still be output: {e}"
            )

        return python_code

    except Exception as e:
        logger.error("Error converting Phiton code: %s", str(e))
        msg = f"Invalid Phiton code: {e!s}"
        raise ValueError(msg)


def calculate_stats(source: str, result: str) -> dict[str, int | float]:
    """Calculate compression statistics.

    Args:
        source: Original Python code
        result: Converted Phiton code

    Returns:
        Dictionary with compression statistics
    """
    return {
        "original_chars": len(source),
        "compressed_chars": len(result),
        "original_lines": len(source.splitlines()),
        "compressed_lines": len(result.splitlines()),
        "compression_ratio": round(len(result) / len(source) * 100, 2),
    }


def print_stats(report: dict[str, int | float]) -> None:
    """Print compression statistics."""
    print("\nCompression Statistics:")
    print(f"Original characters: {report['original_chars']}")
    print(f"Compressed characters: {report['compressed_chars']}")
    print(f"Original lines: {report['original_lines']}")
    print(f"Compressed lines: {report['compressed_lines']}")
    print(f"Compression ratio: {report['compression_ratio']}%")


def convert(
    decompress: bool = False,
    report: bool = False,
    level: int = 5,
    comments: bool = True,
    type_hints: bool = True,
    minify: bool = True,
    symbols: bool = True,
    input_path: str | Path | None = None,
    output_path: str | Path | None = None,
    verbose: bool = False,
) -> None:
    """Convert between Python and Phiton notation.

    Args:
        input_path: input_path file path or '-' for stdin
        output_path: output_path file path or '-' for stdout
        decompress: If True, convert from Phiton to Python
        report: Show compression statistics
        level: Compression level (1-5)
        comments: Whether to preserve comments in output_path
        type_hints: Whether to include type hints in output_path
        minify: Whether to compress whitespace
        symbols: Whether to use local symbol optimization
        verbose: Enable verbose logging
    """
    # Configure logging based on verbose flag
    logger.remove()
    logger.add(sys.stderr, level="DEBUG" if verbose else "INFO")

    try:
        # Read input_path
        if input_path is None or input_path == "-":
            logger.debug("Reading from stdin...")
            source_code = sys.stdin.read()
        else:
            input_path = Path(input_path)
            if not input_path.exists():
                msg = f"input_path file not found: {input_path}"
                raise FileNotFoundError(msg)
            logger.debug(f"Reading from {input_path}...")
            source_code = input_path.read_text(encoding="utf-8")

        # Create configuration
        conv_config = ConversionConfig(
            level=level,
            comments=comments,
            type_hints=type_hints,
            minify=minify,
            symbols=symbols,
        )

        # Convert code
        if decompress:
            logger.debug("Decompressing Phiton to Python...")
            result_code = decompress_from_phiton(source_code, conv_config)
            operation = "decompressed"
        else:
            logger.debug("Compressing Python to Phiton...")
            result_code = compress_to_phiton(source_code, conv_config)
            operation = "compressed"

        # Write output_path
        if output_path is None or output_path == "-":
            logger.debug("Writing to stdout...")
            sys.stdout.write(result_code)
        else:
            output_path = Path(output_path)
            logger.debug(f"Writing to {output_path}...")
            output_path.write_text(result_code, encoding="utf-8")

        # Show statistics if requested
        if report and operation == "compressed":
            stats_data = calculate_stats(source_code, result_code)
            print_stats(stats_data)

        logger.debug(f"Successfully {operation} code")

    except Exception as e:
        logger.error(f"Error: {e!s}")
        sys.exit(1)


def main() -> None:
    """Main entry point for phiton."""
    try:
        fire.Fire(convert)
    except Exception as e:
        logger.error(f"Error: {e!s}")
        sys.exit(1)


if __name__ == "__main__":
    main()
